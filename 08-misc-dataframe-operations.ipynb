{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://edlitera-images.s3.us-east-1.amazonaws.com/new_edlitera_logo.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge DataFrames\n",
    "\n",
    "* Similar functionality to VLOOKUP in Excel\n",
    "<br><br>\n",
    "* Useful when data is distributed across multiple files / database tables\n",
    "<br><br>\n",
    "* we match rows from one DataFrame to rows in another DataFrame\n",
    "    * the row matching is done on \"keys\"\n",
    "        * these are either DataFrame columns or the row index\n",
    "<br><br>        \n",
    "* Several ways to merge two DataFrames: left merge, right merge, inner merge, outer merge, cross merge (recently added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.DataFrame({\n",
    "    'Letter': ['a', 'b', 'c', 'd', 'n', 'o'],\n",
    "    'Country': ['Andorra', 'Belgium', 'Croatia', 'Denmark', 'Niger', 'Oman']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = pd.DataFrame( {\n",
    "    'Name': ['Andorra', 'Denmark', 'Spain', 'Portugal'], \n",
    "    'Capital': ['Andorra la Vella', 'Copenhagen', 'Madrid', 'Lisbon']\n",
    "} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we want to look up the capital city of each country and append it to our `countries` DataFrame\n",
    "* essentially an Excel VLOOKUP\n",
    "    * we want to match the `Country` values in `countries` to the `Name` values in `capitals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a new DataFrame object is created\n",
    "<br><br>\n",
    "* columns from both DataFrames are added to the result\n",
    "    * if there are columns with identical names, a suffix will be added to each resulting column (e.g. `country_x`, `country_y`)\n",
    "<br><br>\n",
    "* **ALL rows from the left-hand side DataFrame are included**\n",
    "<br><br>\n",
    "* **right-hand side DataFrame rows are included ONLY IF they match**\n",
    "    * for our example, the country names are the keys on which we match rows from the right-hand side DataFrame (`capitals`) to rows in the left-hand side DataFrame (`countries`)\n",
    "    * we include rows from the `capitals` DataFrame only if the country name in those rows matches a country name in the `countries` DataFrame\n",
    "<br><br>\n",
    "* similar to a SQL left outer join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.us-east-1.amazonaws.com/left_merge.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_on='Name', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a new DataFrame object is created\n",
    "<br><br>\n",
    "* columns from both DataFrames are added to the result\n",
    "    * if there are columns with identical names, a suffix will be added to each resulting column (e.g. `country_x`, `country_y`)\n",
    "<br><br>\n",
    "* **ALL rows from the right-hand side DataFrame are included**\n",
    "<br><br>\n",
    "* **left-hand side DataFrame rows are included ONLY IF they match**\n",
    "    * for our example, the country names are the keys on which we match rows from the left-hand side DataFrame (`countries`) to rows in the right-hand side DataFrame (`capitals`)\n",
    "    * we include data from the `countries` DataFrame only if the country name in those rows matches a country name in the `capitals` DataFrame    \n",
    "<br><br>\n",
    "* similar to a SQL right outer join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.us-east-1.amazonaws.com/right_merge.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_on='Name', \n",
    "    how='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a new DataFrame object is created\n",
    "<br><br>\n",
    "* columns from both DataFrames are added to the result\n",
    "    * if there are columns with identical names, a suffix will be added to each resulting column (e.g. `country_x`, `country_y`)\n",
    "<br><br>\n",
    "* **ONLY rows that have key values present in both DataFrames are included**\n",
    "    * i.e. if we merge on country names, only rows that have country names that are present in **both** DataFrames are included\n",
    "<br><br>\n",
    "* similar to a SQL inner join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.us-east-1.amazonaws.com/inner_merge.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_on='Name', \n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a new DataFrame object is created\n",
    "<br><br>\n",
    "* columns from both DataFrames are added to the result\n",
    "    * if there are columns with identical names, a suffix will be added to each resulting column (e.g. `country_x`, `country_y`)\n",
    "<br><br>\n",
    "* **ALL rows from both DataFrames are included**\n",
    "<br><br>\n",
    "* similar to a SQL full outer join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.us-east-1.amazonaws.com/outer_merge.png\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_on='Name', \n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging using the row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1\n",
    "\n",
    "capitals.set_index('Name', inplace=True)\n",
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_index=True, \n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = capitals.reset_index()\n",
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2\n",
    "\n",
    "pd.merge(\n",
    "    countries, capitals, \n",
    "    left_index=True, right_index=True, \n",
    "    how='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: `merge` DOES NOT modify any of the dataframes in place. You need to assign the result to a variable to store it for future use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    countries, capitals, \n",
    "    left_on='Country', right_on='Name', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging on multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It's not possible :(\n",
    "* BUT: remember, you can always create \"artificial\" keys!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"first_name\": [\"James\", \"Janet\", \"Jamie\"],\n",
    "    \"last_name\": [\"Bond\", \"Brown\", \"Baker\"],\n",
    "    \"phone_numbers\": [\"555-1111\", \"555-1010\", \"555-0010\"]\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    \"name\": [\"James Bond\", \"Janet Brown\", \"Jamie Baker\"],\n",
    "    \"id\": [\"007\", \"008\", \"009\"]\n",
    "})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we merge these DataFrames?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Start by creating any required artificial keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"first_name\"] + \" \" + df1[\"last_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"name\"] = df1[\"first_name\"] + \" \" + df1[\"last_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And then merge away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    df1, df2, \n",
    "    left_on=\"name\", right_on=\"name\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to do the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe, call it `customers`, that has two columns, `Customer ID` and `Customer Name`. Store the following data in this dataframe:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Customer ID</th>\n",
    "        <th>Customer Name</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1234</td>\n",
    "        <td>James</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3034</td>\n",
    "        <td>Eileen</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a dataframe, call it `orders`, that has two columns, `Reference ID` and `Amount`. Store the following data in this dataframe:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Reference ID</th>\n",
    "        <th>Amount</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>30-34</td>\n",
    "        <td>20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>30-34</td>\n",
    "        <td>17</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>12-34</td>\n",
    "        <td>12</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>12-34</td>\n",
    "        <td>27</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>30-34</td>\n",
    "        <td>21</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>40-01</td>\n",
    "        <td>25</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Merge the two dataframes such that, for each order we can see the customer name. Store the result in `data`. Note that the `Reference ID` has an extra `-` that you will have to remove before you can do the merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are all the purchases made by Eileen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.DataFrame( {\n",
    "    'Customer ID': [1234, 3034], \n",
    "    'Customer Name': ['James', 'Eileen'] \n",
    "} )\n",
    "\n",
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.DataFrame( {\n",
    "    'Reference ID': ['30-34', '30-34', '12-34', \n",
    "                     '12-34', '30-34', '40-01'], \n",
    "    'Amount': [20, 17, 12, 27, 21, 25]\n",
    "} )\n",
    "\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Merge the two dataframes such that, for each order we can see the customer name. Store the result in `data`. Note that the `Reference ID` has an extra `-` that you will have to remove before you can do the merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['Customer ID'] = (\n",
    "    orders['Reference ID']\n",
    "    .str\n",
    "    .replace('-', '')\n",
    "    .astype('int')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    orders, customers, \n",
    "    left_on='Customer ID', right_on='Customer ID', \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are all the purchases made by Eileen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ data['Customer Name'] == 'Eileen' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv\"\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `sort_values()` to sort a dataframe\n",
    "* sorting can be done in place (`inplace=True`)\n",
    "* or can be achieved by creating a new (sorted) DataFrame object (`inplace=False`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(\n",
    "    by='Helpfulness', \n",
    "    ascending=False, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(\n",
    "    by=['Helpfulness', 'Courtesy'], \n",
    "    ascending=[True, False], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, there are a few things we can do when we have missing (`NaN`) values:\n",
    "    \n",
    "* we can drop any row that has a missing value\n",
    "* we can drop any column that has a missing value\n",
    "* we can replace missing values with some default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\n",
    "    \"https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv\", \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "dt['Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping rows that have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dropna(inplace=True)\n",
    "\n",
    "dt['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill `NaN` values with some default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\n",
    "    \"https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv\", \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "dt['Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Location'].fillna('store', inplace=True)\n",
    "\n",
    "dt['Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More generally, you can also `replace` a value with another value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\n",
    "    \"https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv\", \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "dt['Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt['Location'].replace('online', 'store', inplace=True)\n",
    "\n",
    "dt['Location'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Location'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use the following files:\n",
    "    \n",
    "* `survey_sample.csv`, available here: https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv \n",
    "<br><br>\n",
    "* `survey_mappings.xlsx`, available here: https://edlitera-datasets.s3.amazonaws.com/survey_mappings.xlsx, which has two sheets, `Departments` and `Reps`\n",
    "<br><br>\n",
    "* `customer_ltv.xlsx`, available here: https://edlitera-datasets.s3.amazonaws.com/customer_ltv.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the files above into the following data frames:\n",
    "* `data`, which stores the survey sample data (`survey_sample.csv`)\n",
    "<br><br>\n",
    "* `departments`, which stores a mapping of department codes to department names (the `Departments` sheet of the `survey_mappings.xlsx` file)\n",
    "<br><br>\n",
    "* `reps`, which stores a mapping of rep IDs to rep names (the `Reps` sheet of the `survey_mappings.xlsx` file)\n",
    "<br><br>\n",
    "* `ltv`, which stores our customers' life-time value (i.e. how much money they spent with us so far; the data is available in the `customer_ltv.xlsx` file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write code to perform the following actions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) look up the name of each of the reps and add it to the survey data (`data`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) taking into account that the first two digits of the rep id code are the department code (the department where the cutomer representative works), add the Department name to the survey data as a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) add the life-time value to the survey data (`data`) as a new column and fill it in for customers who have purchased from our stores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) for customers that have not purchased from our stores, fill in the default life-time value of 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv', \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments = pd.read_excel(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_mappings.xlsx',\n",
    "    'Departments'\n",
    ")\n",
    "\n",
    "departments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = pd.read_excel(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_mappings.xlsx',\n",
    "    'Reps'\n",
    ")\n",
    "\n",
    "reps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv = pd.read_excel('https://edlitera-datasets.s3.amazonaws.com/customer_ltv.xlsx')\n",
    "\n",
    "ltv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) look up the name of each of the reps and add it to the survey data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    data, reps, \n",
    "    left_on='Rep Id', right_on='Rep Id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) taking into account that the first two digits of the rep id code are the department code (the department where the cutomer representative works), add the Department name to the survey data as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a column that stores\n",
    "# only the first 2 digits of the Rep Id\n",
    "\n",
    "data['Department Id'] = data['Rep Id'].astype(str).str[:2]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `Code` column in the departments DataFrame\n",
    "# is an int64, while the newly created `Department Id`\n",
    "# column in the data DataFrame is an object. We know\n",
    "# we'll need to merge on these columns, so we need to\n",
    "# convert them to the same data type\n",
    "\n",
    "data['Department Id'] = data['Department Id'].astype(departments['Code'].dtype)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we can do a regular merge\n",
    "\n",
    "data = pd.merge(\n",
    "    data, departments, \n",
    "    left_on='Department Id', right_on='Code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `Department Id` and `Code` columns contain\n",
    "# the same data, so we can drop one of them\n",
    "data.drop(columns=['Code'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3) add the life-time value as a new column and fills it in for customers who have purchased from us**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    data, ltv, \n",
    "    left_on='Customer Id', right_on='Customer Id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) for customers that have not purchased from our stores, fill in the default life-time value of 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Amount'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ data['Amount'].isnull() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ data['Amount'].isnull() ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Amount'].fillna(0, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ data['Amount'].isnull() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to set a custom DataFrame index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv', \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use the `set_index()` method to set a custom index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `set_index()` method has an optional `inplace` argument we can use to modify DataFrames in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can create a multi-index by using several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv', \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "data.set_index( ['Date', 'Location'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(['Date', 'Location']).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can actually avoid removing the column(s) you designate as row the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'https://edlitera-datasets.s3.amazonaws.com/survey_sample.csv', \n",
    "    parse_dates=['Date']\n",
    ")\n",
    "\n",
    "data.set_index('Date', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating multiple DataFrames objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use cases:\n",
    "\n",
    "* appending rows to existing DataFrames\n",
    "    * e.g. when we have to combine multiple files\n",
    "<br><br>    \n",
    "* appending columns from one DataFrame (or file) to another DataFrame    \n",
    "<br><br>\n",
    "* achieved using the `concat` method\n",
    "    * https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    * works for both `Series` and `DataFrame` objects\n",
    "    \n",
    "<br><br>    \n",
    "#### Difference between `merge` and `concat`\n",
    "* `merge` combines DataFrames based on shared values\n",
    "* `concat` appends rows / columns from a DataFrame to another DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames\n",
    "* very useful when combining multiple files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 5],\n",
    "    'col2': ['a', 'b', 'c', 'd', 'e']\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'col1': [10, 20, 30, 40, 50],\n",
    "    'col3': ['Andorra', 'Belgium', 'Canada', 'Denmark', 'Estonia']\n",
    "})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To understand `concat`, we must understand the concept of `axes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.amazonaws.com/dataframe_axis.png\" width=\"450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two ways to concatenate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://edlitera-images.s3.amazonaws.com/concat_axes.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can append the rows of one DataFrame to another DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df1, df2],  axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** By default, `axis=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can append the columns of one DataFrame to another DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df1, df2], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'col1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Generally, column names should be unique. Duplicate column names can cause confusion, resulting in code bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When concatenating DataFrames, we can identify the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(\n",
    "    [df1, df2], \n",
    "    keys=['source1', 'source2']\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(\n",
    "    [df1, df2], \n",
    "    keys=['source1', 'source2'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can choose to reset the index labels when concatenating DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When concatenating DataFrames, we can choose to only keep the overlapping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When concatenating DataFrames, we can choose to only keep the rows that have matching index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'col1': [1, 2, 3, 4, 5],\n",
    "    'col2': ['a', 'b', 'c', 'd', 'e']}, \n",
    "    index=[1, 2, 3, 7, 8])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'col1': [10, 20, 30, 40, 50], \n",
    "    'col3': ['Andorra', 'Belgium', 'Canada', 'Denmark', 'Estonia']}, \n",
    "    index=[1, 2, 3, 20, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], join='inner', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_processing_environment",
   "language": "python",
   "name": "data_processing_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
